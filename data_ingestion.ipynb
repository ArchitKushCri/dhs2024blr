{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will learn how to create a data ingenstion pipeline to add data to a vector database. We are going to use `Pinecone` as the vector database, but there are other vector databases available too for example `Chroma, Weaviate, Faiss, etc.`\n",
    "\n",
    "We will be doing the following in this session:\n",
    "- How to load in documents.\n",
    "- Add metadata to each document.\n",
    "- How to use a text splitter to split documents.\n",
    "- How to generate embeddings for each text chunk.\n",
    "- How to insert into a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](../images/data_ingestion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You will need a [Pinecone](https://www.pinecone.io/) API key, you can [sign-up](https://app.pinecone.io/?sessionType=signup) for free to get a started account and then get the API key after sign-up.\n",
    "\n",
    "- You will need an [OpenAI](https://openai.com/) api key for this session. It will be provided by Analytics Vidhya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pinecone in c:\\users\\architk\\appdata\\roaming\\python\\python311\\site-packages (5.0.0)\n",
      "Requirement already satisfied: pinecone-client==5.0.0 in c:\\users\\architk\\appdata\\roaming\\python\\python311\\site-packages (from pinecone) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from pinecone-client==5.0.0->pinecone) (2023.7.22)\n",
      "Requirement already satisfied: pinecone-plugin-inference==1.0.2 in c:\\users\\architk\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client==5.0.0->pinecone) (1.0.2)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\architk\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client==5.0.0->pinecone) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pinecone-client==5.0.0->pinecone) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\architk\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client==5.0.0->pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pinecone-client==5.0.0->pinecone) (1.26.16)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client==5.0.0->pinecone) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Import the 'os' module for interacting with the operating system\n",
    "import os\n",
    "\n",
    "# Import the 'time' module for handling time-related tasks\n",
    "import time  \n",
    "\n",
    "!pip install pinecone\n",
    "# Import the 'Pinecone' class from the 'pinecone' package for vector database operations\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Import the 'ServerlessSpec' class from the 'pinecone' package for serverless deployment specifications\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# To create embeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# To connect with the Vectorstore\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# To parse the PDFs\n",
    "from langchain_community.document_loaders import PyPDFLoader \n",
    "\n",
    "# To load files in a directory\n",
    "from langchain_community.document_loaders import DirectoryLoader \n",
    "\n",
    "# To split the text into smaller chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OPENAI_API_KEY environment variable to your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# Set the PINECONE_API_KEY environment variable to your Pinecone API key\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"8b0aba5e-46f0-4463-8872-4bd81ca57ceb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a ServerlessSpec object for AWS with the specified region\n",
    "spec = ServerlessSpec(cloud='aws', \n",
    "                      region='us-east-1')\n",
    "\n",
    "# configure client  \n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])  \n",
    "\n",
    "INDEX_NAME = 'dhs2024blr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with name `dhs2024blr` is created\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# Check if the index already exists in the current PC (presumably a database or similar)\n",
    "if INDEX_NAME in pc.list_indexes().names():\n",
    "    # If the index exists, print a message indicating its existence\n",
    "    print(f\"Index `{INDEX_NAME}` already exists\")\n",
    "    \n",
    "    # Retrieve the existing index object\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    \n",
    "    # Print detailed statistics about the existing index\n",
    "    print(index.describe_index_stats())\n",
    "    \n",
    "# If the index does not exist, proceed to create a new one\n",
    "else:\n",
    "    # Create a new index with specific parameters\n",
    "    pc.create_index(\n",
    "            INDEX_NAME,\n",
    "            dimension=1536,  # dimensionality of text-embedding-ada-002\n",
    "            metric='cosine',\n",
    "            spec=spec\n",
    "        )\n",
    "    \n",
    "    # Wait for the index to be initialized before proceeding\n",
    "    while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "        # Sleep for 1 second to avoid overloading the system with requests\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Once the index is ready, print a confirmation message\n",
    "    print(f\"Index with name `{INDEX_NAME}` is created\")\n",
    "    \n",
    "    # Retrieve the newly created index object\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    \n",
    "    # Print detailed statistics about the newly created index\n",
    "    print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note:` In case you want to delete an already existing index then use the following `pc.delete_index(index_name)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path where the data files are stored\n",
    "DATA_DIR_PATH = \"../data/\"\n",
    "\n",
    "# Set the chunk size for processing data, typically in bytes\n",
    "CHUNK_SIZE = 1024\n",
    "\n",
    "# Define the overlap between chunks for more efficient processing\n",
    "CHUNK_OVERLAP = 204\n",
    "\n",
    "# Specify the name of the index to be used for storing or retrieving data\n",
    "INDEX_NAME = 'av-earnings-call'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note:` Make sure to maintain the below show directory structure since we will be using the Year and Quarter directory names in the metadata later.\n",
    "\n",
    "![Alt text](../images/data_dir_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files\n",
    "\n",
    "Initialize a DirectoryLoader object and pass the `Path to data`, `the type of files to load from directory`, and `the loader_class` which in our case is PyPDFLoader since we are working with PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 29\n"
     ]
    }
   ],
   "source": [
    "# Initialize a loader object with your specific loading logic or method\n",
    "loader = DirectoryLoader(path=DATA_DIR_PATH, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "# Load documents using the loader object\n",
    "docs = loader.load()\n",
    "\n",
    "# Print the total number of documents loaded\n",
    "print(f\"Total documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 0}, page_content=' \\n Page 1 of 18  \\n \\n“HCL  Tech nologies Limited ’s Q4FY23 & Annual FY23 \\nEarnings Conference Call”  \\n \\nApril 20 , 2023 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\nMANAGEMENT : MR. C. VIJAYAKUMAR – CHIEF EXECUTIVE OFFICER & \\nMANAGING DIRECTOR , HCL  TECH NOLOGIES LIMITED  \\nMR. PRATEEK  AGGARWAL  – CHIEF  FINANCIAL \\nOFFICER , HCL  TECH NOLOGIES LIMITED  \\nMR. SRINIVASAN SESHADRI – GLOBAL HEAD, \\nFINANCIAL SERVICES , HCL  TECH NOLOGIES LIMITED  \\nMR. VIJAY GUNTUR  – PRESIDEN T, ENGINEERING AND \\nR&D  SERVICES , HCL  TECH NOLOGIES LIMITED  \\nMR. MANAN  BATRA – SENIOR MANAGER , INVESTOR \\nRELATIONS , HCL  TECH NOLOGIES LIMITED  \\n  \\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking into the first document\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys associated with a Document: dict_keys(['id', 'metadata', 'page_content', 'type'])\n"
     ]
    }
   ],
   "source": [
    "# we can convert the Document object to a python dict using the .dict() method.\n",
    "print(f\"keys associated with a Document: {docs[0].dict().keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "First 100 charachters of the page content:  \n",
      " Page 1 of 18  \n",
      " \n",
      "“HCL  Tech nologies Limited ’s Q4FY23 & Annual FY23 \n",
      "Earnings Conference Call”  \n",
      "---------------\n",
      "Metadata associated with the document: {'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 0}\n",
      "---------------\n",
      "\\data\\FY23\\Q4\\HCLTech\n",
      "Datatype of the document: Document\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'-'*1}\\nFirst 100 charachters of the page content: {docs[0].page_content[:100]}\\n{'-'*15}\")\n",
    "print(f\"Metadata associated with the document: {docs[0].metadata}\\n{'-'*15}\")\n",
    "fname = docs[0].metadata['source']\n",
    "print(str(fname).split('\\\\')[-1])\n",
    "print(f\"Datatype of the document: {docs[0].type}\\n{'-'*15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We loop through each document and add additional metadata - filename, quarter, and year\n",
    "for doc in docs:\n",
    "    filename = doc.dict()['metadata']['source'].split('\\\\')[-1]\n",
    "    quarter = doc.dict()['metadata']['source'].split('\\\\')[-2]\n",
    "    year = doc.dict()['metadata']['source'].split('\\\\')[-3]\n",
    "    doc.metadata = {\"filename\": filename, \"quarter\": quarter, \"year\": year, \"source\": doc.dict()['metadata']['source'], \"page\": doc.dict()['metadata']['page']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata associated with the document: {'filename': 'HCLTech.pdf', 'quarter': 'Q4', 'year': 'FY23', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 0}\n",
      "---------------\n",
      "Metadata associated with the document: {'filename': 'HCLTech.pdf', 'quarter': 'Q4', 'year': 'FY23', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 1}\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# To veryfy that the metadata is indeed added to the document\n",
    "print(f\"Metadata associated with the document: {docs[0].metadata}\\n{'-'*15}\")\n",
    "print(f\"Metadata associated with the document: {docs[1].metadata}\\n{'-'*15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking Text\n",
    "\n",
    "As the name suggests, chunking is the process of dividing a large amount of data into several smaller parts for more effective and meaningful storage.\n",
    "\n",
    "There are various ways to perform chunking naming some as:\n",
    " - Character Chunking\n",
    " - Recursive Character Chunking\n",
    " - Document Specific Chunking\n",
    "\n",
    "For the sake of this session we will be using the `Recursive Character Chunking` and langchain has an implemention that we can directly use. To read more about it you can refer to the [docs](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/)\n",
    "\n",
    "`Additional Resource:` If you want to explore the different chunking stratigies than you can refer to the following docs from langchain - [Link to Docs](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "     chunk_size=CHUNK_SIZE,\n",
    "     chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 112)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'filename': 'HCLTech.pdf', 'quarter': 'Q4', 'year': 'FY23', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 0}, page_content='Page 1 of 18  \\n \\n“HCL  Tech nologies Limited ’s Q4FY23 & Annual FY23 \\nEarnings Conference Call”  \\n \\nApril 20 , 2023 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\nMANAGEMENT : MR. C. VIJAYAKUMAR – CHIEF EXECUTIVE OFFICER & \\nMANAGING DIRECTOR , HCL  TECH NOLOGIES LIMITED  \\nMR. PRATEEK  AGGARWAL  – CHIEF  FINANCIAL \\nOFFICER , HCL  TECH NOLOGIES LIMITED  \\nMR. SRINIVASAN SESHADRI – GLOBAL HEAD, \\nFINANCIAL SERVICES , HCL  TECH NOLOGIES LIMITED  \\nMR. VIJAY GUNTUR  – PRESIDEN T, ENGINEERING AND \\nR&D  SERVICES , HCL  TECH NOLOGIES LIMITED  \\nMR. MANAN  BATRA – SENIOR MANAGER , INVESTOR \\nRELATIONS , HCL  TECH NOLOGIES LIMITED'),\n",
       " Document(metadata={'filename': 'HCLTech.pdf', 'quarter': 'Q4', 'year': 'FY23', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 1}, page_content=\"HCL Tech nologies Limited  \\nApril 20 , 202 3 \\n \\n Page 2 of 18 \\nModerator:  Ladies and gentlemen, g ood day and welcome to the HCL Technologies  Limited Q4 FY'23 & \\nAnnual FY'23 Earnings Conference Call . \\nAs a reminder, all participant lines will be in the listen -only mode and there will be an \\nopportunity for you to ask questions after the presentation concludes.  Should you need assistance \\nduring the conference call,  please signal an operator by pressing ‘*’ then ‘0’  on your touchtone \\nphone.  Please note that this conference is being recorded.  \\nI now hand the conference over to Mr. Manan Batra, Senior Manager, Investor Relations . Thank \\nyou, and over to you, sir.  \\nManan Batra : Thank you, Aman . Good morning and good evening, everyone. A very warm welcome to \\nHCLTech 's Full Year  Fiscal 2023 & Q4 Earnings Call.  \\nWe have with us Mr. C. Vijay akumar  – CEO  and Managing Director , HCLTech ; Mr. Prat eek \\nAggarwal  – Chief  Financial Officer, along with the broader leadership team to discuss the\"),\n",
       " Document(metadata={'filename': 'HCLTech.pdf', 'quarter': 'Q4', 'year': 'FY23', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 1}, page_content='We have with us Mr. C. Vijay akumar  – CEO  and Managing Director , HCLTech ; Mr. Prat eek \\nAggarwal  – Chief  Financial Officer, along with the broader leadership team to discuss the \\nperformance of the company during the  year and the  quarter followed by Q&A. \\nIn the course of this call, certain statements that will be made are forward -looking, which involve \\na numbe r of risks, uncertainties, assumptions, and other factors that could cause actual results to \\ndiffer materially from those in such forward -looking statements. All forward -looking statements \\nmade herein are based on information presently available to the man agement, and the company \\ndoes not undertake to update any forward -looking statements that may be made in the course of \\nthis call. In this regard, please do review the safe harbor statement in the formal investor release \\ndocument and all the factors that ca n cause the difference.  \\nOver to you C VK and thanks.'),\n",
       " Document(metadata={'filename': 'HCLTech.pdf', 'quarter': 'Q4', 'year': 'FY23', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'page': 1}, page_content=\"this call. In this regard, please do review the safe harbor statement in the formal investor release \\ndocument and all the factors that ca n cause the difference.  \\nOver to you C VK and thanks.  \\nC. Vijayakumar:  Thank you, Manan . Good evening  and good morning , everyone. Thank you for joining us for \\nHCLTech 's FY'23 & Q 4 FY'23 Annual Earnings Announcement.  \\nWhen we started the year, there was good optimism around growth supported by strong market \\nmomentum but within an uncertain geopolitical environment. When we started the year, there \\nwas high attrition and increasing resource costs industry -wide. I'm pleased to shar e that we've \\nmanaged to deliver good growth with good control over profitability during such a volatile \\nperiod.  \\nOur overall revenue growth 13.7% in constant currency year -on-year. The strong growth is \\nattributed to good momentum both in our services as wel l as our software business.  This was on\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the vectors already added in DB: (Type Y/N)N\n",
      "New vectorstore is created and loaded\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user to confirm if the vectors are already added to the Pinecone database\n",
    "docs_already_in_pinecone = input(\"Are the vectors already added in DB: (Type Y/N)\")\n",
    "\n",
    "# Check if the user has confirmed that the vectors are already in the database\n",
    "if docs_already_in_pinecone == \"Y\" or docs_already_in_pinecone == \"y\":\n",
    "    \n",
    "    # Initialize a PineconeVectorStore object with the existing index and embeddings\n",
    "    docsearch = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)\n",
    "    \n",
    "    print(\"Existing Vectorstore is loaded\")\n",
    "    \n",
    "# If the user confirms that the vectors are not in the database, create a new PineconeVectorStore from the documents and embeddings\n",
    "elif docs_already_in_pinecone == \"N\" or docs_already_in_pinecone == \"n\":\n",
    "    \n",
    "    # Create a PineconeVectorStore object from the documents and embeddings, specifying the index name\n",
    "    docsearch = PineconeVectorStore.from_documents(documents, embeddings, index_name=\"dhs2024blr\")\n",
    "    \n",
    "    print(\"New vectorstore is created and loaded\")\n",
    "    \n",
    "# If the user input is neither 'Y' nor 'N', prompt them to enter a valid response\n",
    "else:\n",
    "    print(\"Please type Y - for yes and N - for no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are defing how to use the loaded vectorstore as retriver\n",
    "retriver = docsearch.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'filename': 'HCLTech.pdf', 'page': 8.0, 'quarter': 'Q4', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'year': 'FY23'}, page_content='months basis, which is at 121% of net income. So, that continues to be at that range of 120% -\\nplus that we have been mentioning in both of our investor days in the last year and as per the \\npromise  that we have made to you. And free cash flow as well came in at $2 billion plus ; $2,024 \\nmillion to be precise , and that comes in at 110% of net income. So, both those metrics are \\nextremely good to look at . \\nOur balance sheet therefore continues to stren gthen with gross cash now at $2.8 billion and net \\ncash at $2.5 billion. Remember, in this quarter, we actually retired $248 million worth of bonds \\nthat we had issued two years back and that reduces the gross cash. Without that , the gross cash \\nwould have bee n $248 million  higher and therefore is $3,058 million  to be precise. But net cash \\nobviously remains the same because it is post reducing the impact of borrowings . Overall DSO \\nreduced by two days on a sequential basis, including (UBR) unbilled  revenue, it now stands at \\n88 da ys.'),\n",
       " Document(metadata={'filename': 'HCLTech.pdf', 'page': 8.0, 'quarter': 'Q4', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'year': 'FY23'}, page_content='obviously remains the same because it is post reducing the impact of borrowings . Overall DSO \\nreduced by two days on a sequential basis, including (UBR) unbilled  revenue, it now stands at \\n88 da ys. \\nShareholders aspects. Ultimately , the net income or profit after tax on a EPS basis, diluted EPS \\nfor the last 12 -months comes in at Rs. 54.79, which is a 10.1% increase on a year -on-year basis.  \\nAnd looking at that, and all the financials and projections, the board is happy to declare dividend \\nat Rs.18 for the quarter, that brings up the full year dividend to Rs.48 per share as we have paid \\nRs.10 per share per quarter in the first three quarter  so, 30 plus 18 for this quarter makes it 48 , \\nand against the 54.79 of EPS th e payout ratio stands at 87.5%. We had promised a minimum of \\n75%. So, we are staying fairly high compared to that. So, hopefully shareholders should  be happy \\nwith that.'),\n",
       " Document(metadata={'filename': 'HCLTech.pdf', 'page': 1.0, 'quarter': 'Q4', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'year': 'FY23'}, page_content='period.  \\nOur overall revenue growth 13.7% in constant currency year -on-year. The strong growth is \\nattributed to good momentum both in our services as wel l as our software business.  This was on \\nback of strong and healthy growth across segments , sectors and geographies with a healthy \\nmargin performance.'),\n",
       " Document(metadata={'filename': 'HCLTech.pdf', 'page': 6.0, 'quarter': 'Q4', 'source': '..\\\\data\\\\FY23\\\\Q4\\\\HCLTech.pdf', 'year': 'FY23'}, page_content=\"have a new page that we've added to this quarter  and the annual  investor release.  \\nSo, apart from providing the revenue by type of sales, we have also added the annual recurring \\nrevenue as a new metric , ARR , which I'm sure you know that typical software businesses  and \\nrelevant stakeholders tend to focus a lot on . So, we've started publishing that from this quarter . \\nAs on 31st March, the ARR stands at $1 billion plus and has shown a growth of 5.2% on a year -\\non-year basis in constant currency.  \\nFor the quarter , EBITDA margin came in at 21.9% and EBIT at 18.1% . I will shortly explain \\nthe quarter -on-quarter variance in EBIT . Net income for the quarter came in at $481 million, \\nwhich was 14.9% and up 1.3% year -on-year.  \\nThe w alk from the previous  December quarter to the current March quarter is actually a very \\nsimple w alk. HCL S oftware seasonality in fact itself is about 125 basis points,  which basically\")]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"what is the income?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using metadata with retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a retriever object using the `docsearch` module, configured with specific search parameters\n",
    "retriver = docsearch.as_retriever(search_kwargs={\"filter\": {\"quarter\": \"Q1\"}, \"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 3.0, 'quarter': 'Q1', 'source': '..\\\\data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'}, page_content='passengers and non -passengers at the airport and secondly , the increase  in the actual gross spend \\nrate of each of the passenger , so these two aspects contributing for the growth in AEL . \\nMohit Kumar : My third question is Carmi chael, is it possible to share the revenues  and EBITDA for the quarter \\nand the related question is that in the segmental which you have disclose d, commercial mining \\nis one line item, I believe this primarily corresponds to Carmichael? I s my understanding \\ncorrect?  \\nRobbie Singh : Yes, the understanding  is correct.  \\nMohit Kumar : My last question is on the Solar PV, we have done a very good job  in the sense the numbers are \\nvery good  for the quarter,  and I believe the exporting of a large amount to the third countries . \\nCan you please specify which are the countries  where we are exporting  our modules right now? \\nSome ballpark number?  \\nRobbie Singh : Primarily, US and Europe , overall.'),\n",
       " Document(metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 1.0, 'quarter': 'Q1', 'source': '..\\\\data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'}, page_content='pipeline. This Q1 FY 24 is powered by the eme rgence of green -hydrogen business , Adani New \\nIndustries Limited that now contributes over 10% of EBITDA.  \\nOur performance for the quarter reflects our strong operation al momentum on the back of ANIL \\necosystem and the incubating business performance. The consolidated total income was at \\nRs.25,810 crores. Consolidated EBITDA increased by 47% year -on-year to Rs. 2,896 crores and \\nin line  with the increase d EBITDA , consolidat ed PAT increased by 44% to Rs. 674 crores. In our \\ncommitment of having  1 gigawatt of data center platform in India, I am pleased to inform you \\nthat AdaniConneX has secured the largest data center project financing deal in India with USD \\n213 million construction facility.  \\nNow for update of some of our incubating businesses : \\nIn Adani New Industries  our green hydrogen ecosystem , during the quarter the integrated \\nmanufacturing division received the  provisional certificate  of 5.2-megawatt  prototype -1 wind')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"what is the income?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
